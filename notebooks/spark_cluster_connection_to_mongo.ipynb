{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d7e074-49fb-4b9f-9f74-3164b89bffc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Fixing Version Compatibility ===\n",
      "Trying with older stable connector version...\n",
      "Downloading MongoDB connector compatible with Spark 3.5.0...\n",
      "✅ mongo-spark-connector_2.12 already exists\n",
      "✅ bson already exists\n",
      "✅ mongodb-driver-core already exists\n",
      "✅ mongodb-driver-sync already exists\n",
      "\n",
      "Using compatible JARs: /tmp/spark_jars_compatible/mongo-spark-connector_2.12-3.0.2.jar,/tmp/spark_jars_compatible/bson-4.6.1.jar,/tmp/spark_jars_compatible/mongodb-driver-core-4.6.1.jar,/tmp/spark_jars_compatible/mongodb-driver-sync-4.6.1.jar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/07 23:05:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Spark session created with compatible JARs!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import subprocess\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# MongoDB connector versions compatible with Spark 3.5.0\n",
    "compatible_jars = {\n",
    "    \"mongo-spark-connector_2.12\": {\n",
    "        \"version\": \"3.0.2\",\n",
    "        \"url\": \"https://repo1.maven.org/maven2/org/mongodb/spark/mongo-spark-connector_2.12/3.0.2/mongo-spark-connector_2.12-3.0.2.jar\"\n",
    "    },\n",
    "    \"bson\": {\n",
    "        \"version\": \"4.6.1\",\n",
    "        \"url\": \"https://repo1.maven.org/maven2/org/mongodb/bson/4.6.1/bson-4.6.1.jar\"\n",
    "    },\n",
    "    \"mongodb-driver-core\": {\n",
    "        \"version\": \"4.6.1\",\n",
    "        \"url\": \"https://repo1.maven.org/maven2/org/mongodb/mongodb-driver-core/4.6.1/mongodb-driver-core-4.6.1.jar\"\n",
    "    },\n",
    "    \"mongodb-driver-sync\": {\n",
    "        \"version\": \"4.6.1\",\n",
    "        \"url\": \"https://repo1.maven.org/maven2/org/mongodb/mongodb-driver-sync/4.6.1/mongodb-driver-sync-4.6.1.jar\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Download compatible versions\n",
    "jar_dir = \"/tmp/spark_jars_compatible\"\n",
    "os.makedirs(jar_dir, exist_ok=True)\n",
    "jar_paths = []\n",
    "\n",
    "print(\"Downloading MongoDB connector compatible with Spark 3.5.0...\")\n",
    "for name, info in compatible_jars.items():\n",
    "    jar_path = os.path.join(jar_dir, os.path.basename(info[\"url\"]))\n",
    "    jar_paths.append(jar_path)\n",
    "    \n",
    "    if not os.path.exists(jar_path):\n",
    "        print(f\"Downloading {name} {info['version']}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(info[\"url\"], jar_path)\n",
    "            file_size = os.path.getsize(jar_path)\n",
    "            print(f\"✅ {name} downloaded ({file_size:,} bytes)\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ {name} download failed: {e}\")\n",
    "    else:\n",
    "        print(f\"✅ {name} already exists\")\n",
    "\n",
    "# Stop current Spark session\n",
    "try:\n",
    "    spark.stop()\n",
    "    print(\"Stopped existing Spark session\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Create Spark session with compatible JARs\n",
    "compatible_jars_list = \",\".join(jar_paths)\n",
    "print(f\"\\nUsing compatible JARs: {compatible_jars_list}\")\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "    .appName(\"MongoDBCompatible\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .config(\"spark.jars\", compatible_jars_list)\n",
    "    .getOrCreate())\n",
    "\n",
    "print(\"✅ Spark session created with compatible JARs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "654f6018-d080-4eda-b3e0-9ed0aeb25e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing with Compatible MongoDB Version ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully connected to MongoDB!\n",
      "Collection schema:\n",
      "root\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- avg_glucose_level: double (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- heart_disease: integer (nullable = true)\n",
      " |-- hypertension: integer (nullable = true)\n",
      " |-- patient_id: integer (nullable = true)\n",
      " |-- smoking_status: string (nullable = true)\n",
      " |-- stroke: integer (nullable = true)\n",
      "\n",
      "Sample data (showing first 5 rows):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+---+-----------------+----+------+-------------+------------+----------+---------------+------+\n",
      "|_id                       |age|avg_glucose_level|bmi |gender|heart_disease|hypertension|patient_id|smoking_status |stroke|\n",
      "+--------------------------+---+-----------------+----+------+-------------+------------+----------+---------------+------+\n",
      "|{695bc8030a46bfc3948de666}|67 |228.69           |36.6|Male  |1            |0           |1         |formerly smoked|1     |\n",
      "|{695bc8030a46bfc3948de667}|61 |202.21           |28.1|Female|0            |0           |2         |never smoked   |1     |\n",
      "|{695bc8030a46bfc3948de668}|80 |105.92           |32.5|Female|1            |0           |3         |never smoked   |1     |\n",
      "|{695bc8030a46bfc3948de669}|49 |171.23           |34.4|Female|0            |0           |4         |smokes         |1     |\n",
      "|{695bc8030a46bfc3948de66a}|79 |174.12           |24.0|Female|0            |1           |5         |never smoked   |1     |\n",
      "+--------------------------+---+-----------------+----+------+-------------+------------+----------+---------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Testing with Compatible MongoDB Version ===\")\n",
    "\n",
    "try:\n",
    "    # Use the older but stable connector format\n",
    "    connection_uri = \"mongodb://admin:password123@mongodb:27017/stroke_prediction_test_connection.patients?authSource=admin\"\n",
    "    \n",
    "    df = (spark.read\n",
    "          .format(\"com.mongodb.spark.sql.DefaultSource\")\n",
    "          .option(\"uri\", connection_uri)\n",
    "          .load())\n",
    "    \n",
    "    print(\"✅ Successfully connected to MongoDB!\")\n",
    "    print(f\"Collection schema:\")\n",
    "    df.printSchema()\n",
    "    \n",
    "    # Try to show data without count first\n",
    "    print(\"Sample data (showing first 5 rows):\")\n",
    "    df.show(5, truncate=False)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Compatible version failed: {str(e)}\")\n",
    "    print(\"Trying alternative approach...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158aa346-2cfd-49c3-bd11-18a6a53f00aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
